{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welcome to Lab 3 for Week 1 Day 4\n",
    "\n",
    "Today we're going to build something with immediate value!\n",
    "\n",
    "In the folder `me` I've put a single file `linkedin.pdf` - it's a PDF download of my LinkedIn profile.\n",
    "\n",
    "Please replace it with yours!\n",
    "\n",
    "I've also made a file called `summary.txt`\n",
    "\n",
    "We're not going to use Tools just yet - we're going to add the tool tomorrow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/tools.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#00bfff;\">Looking up packages</h2>\n",
    "            <span style=\"color:#00bfff;\">In this lab, we're going to use the wonderful Gradio package for building quick UIs, \n",
    "            and we're also going to use the popular PyPDF PDF reader. You can get guides to these packages by asking \n",
    "            ChatGPT or Claude, and you find all open-source packages on the repository <a href=\"https://pypi.org\">https://pypi.org</a>.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you don't know what any of these packages do - you can always ask ChatGPT for a guide!\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from pypdf import PdfReader\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = PdfReader(\"me/LinkedIn.pdf\")\n",
    "linkedin = \"\"\n",
    "for page in reader.pages:\n",
    "    text = page.extract_text()\n",
    "    if text:\n",
    "        linkedin += text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = PdfReader(\"me/AI_Engineer_NLP_Shreyash_Resume.pdf\")\n",
    "ai_eng = \"\"\n",
    "for page in reader.pages:\n",
    "    text = page.extract_text()\n",
    "    if text:\n",
    "        ai_eng += text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = PdfReader(\"me//Data_Analyst_Shreyash_Sahare_Resume.pdf\")\n",
    "da_role = \"\"\n",
    "for page in reader.pages:\n",
    "    text = page.extract_text()\n",
    "    if text:\n",
    "        da_role += text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = PdfReader(\"me//Data_Engineer_Shreyash_Sahare_Resume.pdf\")\n",
    "de_role = \"\"\n",
    "for page in reader.pages:\n",
    "    text = page.extract_text()\n",
    "    if text:\n",
    "        de_role += text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = PdfReader(\"me//ML_Engineer_Shreyash_Sahare_Resume.pdf\")\n",
    "mle_role = \"\"\n",
    "for page in reader.pages:\n",
    "    text = page.extract_text()\n",
    "    if text:\n",
    "        mle_role += text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = PdfReader(\"me//Data_Scientist_Shreyash_Sahare_Resume.pdf\")\n",
    "ds_role = \"\"\n",
    "for page in reader.pages:\n",
    "    text = page.extract_text()\n",
    "    if text:\n",
    "        ds_role += text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \n",
      "Contact\n",
      "work.shreyash1001@gmail.com\n",
      "www.linkedin.com/in/\n",
      "shreyashsahare28 (LinkedIn)\n",
      "github.com/ShreCodes2809\n",
      "(Personal)\n",
      "Top Skills\n",
      "LLM Evaluation\n",
      "Time Series Analysis\n",
      "Time Series Forecasting\n",
      "Languages\n",
      "Marathi (Limited Working)\n",
      "Spanish (Elementary)\n",
      "English (Full Professional)\n",
      "Hindi (Professional Working)\n",
      "Certifications\n",
      "Programming for Everybody(Getting\n",
      "Started with Python)\n",
      "Python Programming: A Concise\n",
      "Introduction\n",
      "Neural Networks in Python from\n",
      "Scratch: A Complete Guide\n",
      "Snowflake Snowpro Core\n",
      "Generative AI: Introduction and\n",
      "Applications\n",
      "Publications\n",
      "ResCoWNet: A Novel Deep Learning\n",
      "Approach for Despeckling OCT\n",
      "Images\n",
      "Shreyash Sahare\n",
      "Machine Learning Engineer | Ex-Data Scientist at Parlay Finance\n",
      "| 3+ Years in Predictive Modeling, LLMs & Scalable ML Pipelines |\n",
      "Python, SQL, R | Deep Learning, Fine-Tuning, GenAI\n",
      "Boulder, Colorado, United States\n",
      "Summary\n",
      "I'm a Machine Learning Engineer and Data Scientist with a strong\n",
      "background in AI, data engineering, and software systems. I enjoy\n",
      "building end-to-end machine learning solutions—whether that's\n",
      "designing scalable ETL pipelines, training predictive models, or\n",
      "deploying real-time analytics systems in the cloud.\n",
      "Over the past few years, I’ve worked on projects across finance,\n",
      "supply chain, and healthcare. From creating SBA loan classifiers that\n",
      "improved approval workflows, to building explainable AI tools with\n",
      "SHAP and LIME, to developing semantic search systems using RAG\n",
      "and GPT-4o—I’ve had the chance to solve meaningful problems with\n",
      "a mix of ML, data engineering, and creativity.\n",
      "I’m comfortable working across the stack: Dockerized pipelines\n",
      "with Airflow, MLOps with MLflow, and cloud platforms like AWS,\n",
      "GCP, and Azure are part of my regular toolkit. I also love diving into\n",
      "GenAI and LLMs—especially exploring how they can make decision\n",
      "systems more transparent and user-friendly.\n",
      "At the end of the day, I care about more than just accuracy. I like\n",
      "to think about how models will actually be used—how they can be\n",
      "trusted, interpreted, and tied to real business outcomes. I’m always\n",
      "open to learning, collaborating, and pushing the boundaries of what’s\n",
      "possible with AI and data.\n",
      "Experience\n",
      "Void Robotics\n",
      "Robotics Engineering Intern\n",
      "August 2025 - Present (4 months)\n",
      "Marathon, Florida, United States\n",
      "  Page 1 of 4   \n",
      "As a Robotics Engineering Intern at Void Robotics, I worked at the intersection\n",
      "of AI and robotics by developing perception and computer vision pipelines\n",
      "within ROS2. I built a pill-counting system across 50+ images using K-Means\n",
      "clustering and advanced CV techniques such as Lab color space conversion,\n",
      "thresholding, watershed, and masking to accurately detect and mark objects.\n",
      "Building on this foundation, I expanded into robotics AI by implementing\n",
      "SLAM-based autonomous navigation in ROS2 and deploying YOLO-driven\n",
      "object detection in Docker for real-time robotic perception, establishing a\n",
      "scalable path toward intelligent, data-driven robotic systems.\n",
      "Mercor\n",
      "Data Science Expert\n",
      "August 2025 - September 2025 (2 months)\n",
      "San Francisco, California, United States\n",
      "As an Independent Contractor at Mercor, I was expected to execute end-\n",
      "to-end data science tasks and evaluate the reasoning capabilities of state-\n",
      "of-the-art LLMs. I completed 20+ projects across diverse datasets involving\n",
      "hypothesis testing, time series forecasting, clustering, and data preprocessing,\n",
      "while also creating visualizations and insights. Beyond analysis, I crafted\n",
      "challenging prompts for LLMs, authored expert golden responses, and\n",
      "developed detailed rubrics to benchmark model performance. These\n",
      "evaluation frameworks consistently drove SOTA models to score below 50%,\n",
      "averaging 27% across tasks, highlighting reasoning gaps and strengthening\n",
      "the rigor of AI evaluation.\n",
      "Parlay Finance\n",
      "Data Scientist\n",
      "January 2025 - May 2025 (5 months)\n",
      "Alexandria, Virginia, United States\n",
      "- Developed an ML-powered SBA loan eligibility classification system using\n",
      "XGBoost, LightGBM, TabTransformer, and Neural Networks, that achieved\n",
      "87% accuracy and double-digit F1-score improvements through a stacked\n",
      "ensemble model. \n",
      "- Generating a 200K+ row synthetic dataset simulating real-world loan\n",
      "applications, applying SMOTE and random oversampling to balance five\n",
      "eligibility classes capped at 15K samples each\n",
      "  Page 2 of 4   \n",
      "- Engineered key financial features (DSCR, DTI, liquidity scores) with\n",
      "polynomial/log transformations, and integrated SHAP and LIME for model\n",
      "explainability and regulatory transparency. \n",
      "- Reduced loan processing times from weeks to hours, enabling faster, fairer\n",
      "credit access for small businesses.\n",
      "National Institute of Technology, Tiruchirappalli\n",
      "Undergraduate Research Intern\n",
      "June 2022 - August 2022 (3 months)\n",
      "Tamil Nadu, India\n",
      "As an Undergraduate Research Intern under the guidance of my college\n",
      "professor, I actively contributed to advancing medical imaging techniques\n",
      "through cutting-edge research and development. My role involved designing a\n",
      "novel deep convolutional neural network, ResCoWNet, specifically tailored for\n",
      "Optical Coherence Tomography (OCT) image despeckling, using Python and\n",
      "TensorFlow.\n",
      "My work culminated in the publication of findings in a peer-reviewed journal,\n",
      "positioning ResCoWNet as a benchmark in medical imaging. This experience\n",
      "honed my skills in machine learning for healthcare applications, academic\n",
      "writing, and data visualization, while deepening my understanding of advanced\n",
      "image processing techniques.\n",
      "Probe, NIT Trichy\n",
      "1 year 8 months\n",
      "Head of Mentorship Program(Student Relations)\n",
      "August 2021 - August 2022 (1 year 1 month)\n",
      "Tiruchirappalli, Tamil Nadu, India\n",
      "Coordinator\n",
      "January 2021 - August 2021 (8 months)\n",
      "Tiruchirappalli, Tamil Nadu, India\n",
      "Pragyan - International Techno-managerial Organisation\n",
      "Manager, Crossfires and Guest Lectures\n",
      "July 2021 - August 2022 (1 year 2 months)\n",
      "Tiruchirappalli, Tamil Nadu, India\n",
      "National Institute of Technology, Tiruchirappalli\n",
      "Undergraduate Research Assistant\n",
      "  Page 3 of 4   \n",
      "July 2021 - January 2022 (7 months)\n",
      "Tiruchirappalli, Tamil Nadu, India\n",
      "Education\n",
      "University of Colorado Boulder\n",
      "Master's degree, Computer Science · (August 2023 - May 2025)\n",
      "National Institute of Technology, Tiruchirappalli\n",
      "Bachelor of Technology - BTech, Electronics and Communication\n",
      "Engineering · (July 2019 - May 2023)\n",
      "City International School, Wanowrie\n",
      "Student, High School · (2017 - 2019)\n",
      "Hutchings High School & Junior College\n",
      "Student, Schooling · (2005 - 2017)\n",
      "  Page 4 of 4\n"
     ]
    }
   ],
   "source": [
    "print(linkedin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"me/summary.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    summary = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"Shreyash Sahare\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = f\"You are acting as {name}. You are answering questions on {name}'s website, \\\n",
    "particularly questions related to {name}'s career, background, skills and experience. \\\n",
    "Your responsibility is to represent {name} for interactions on the website as faithfully as possible. \\\n",
    "You are given a summary of {name}'s background and LinkedIn profile which you can use to answer questions. \\\n",
    "Be professional and engaging, as if talking to a potential client or future employer who came across the website. \\\n",
    "If you don't know the answer, say so.\"\n",
    "\n",
    "system_prompt += f\"\\n\\n## Summary:\\n{summary}\\n\\n## LinkedIn Profile:\\n{linkedin}\\n\\n\"\n",
    "system_prompt += f\"With this context, please chat with the user, always staying in character as {name}.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You are acting as Shreyash Sahare. You are answering questions on Shreyash Sahare's website, particularly questions related to Shreyash Sahare's career, background, skills and experience. Your responsibility is to represent Shreyash Sahare for interactions on the website as faithfully as possible. You are given a summary of Shreyash Sahare's background and LinkedIn profile which you can use to answer questions. Be professional and engaging, as if talking to a potential client or future employer who came across the website. If you don't know the answer, say so.\\n\\n## Summary:\\nI am a Machine Learning Engineer and Data Scientist with over three years of experience building scalable AI, data engineering, and machine learning systems. My work spans finance, robotics, and healthcare, where I have developed SBA loan classifiers, explainable AI tools using SHAP and LIME, and semantic search systems powered by RAG and GPT-4o. I regularly work with Airflow, MLflow, and Docker, and have deployed models on AWS, GCP, and Azure. I am deeply interested in Generative AI and large language models, especially in making intelligent systems more interpretable and useful for real business applications.\\n\\nRecently, I worked at Void Robotics on developing ROS2-based computer vision and navigation systems using YOLO and SLAM for real-time robotic perception. At Mercor, I focused on evaluating reasoning capabilities of state-of-the-art LLMs and building robust data science solutions. Earlier, at Parlay Finance, I created an SBA loan eligibility classification system that improved model accuracy and reduced loan processing times significantly. My research experience at NIT Trichy led to the development of ResCoWNet, a convolutional neural network for medical image denoising that was later published in a peer-reviewed journal. I completed my master’s in Computer Science from the University of Colorado Boulder and my bachelor’s in Electronics and Communication Engineering from NIT Trichy.\\n\\n## LinkedIn Profile:\\n\\xa0 \\xa0\\nContact\\nwork.shreyash1001@gmail.com\\nwww.linkedin.com/in/\\nshreyashsahare28 (LinkedIn)\\ngithub.com/ShreCodes2809\\n(Personal)\\nTop Skills\\nLLM Evaluation\\nTime Series Analysis\\nTime Series Forecasting\\nLanguages\\nMarathi (Limited Working)\\nSpanish (Elementary)\\nEnglish (Full Professional)\\nHindi (Professional Working)\\nCertifications\\nProgramming for Everybody(Getting\\nStarted with Python)\\nPython Programming: A Concise\\nIntroduction\\nNeural Networks in Python from\\nScratch: A Complete Guide\\nSnowflake Snowpro Core\\nGenerative AI: Introduction and\\nApplications\\nPublications\\nResCoWNet: A Novel Deep Learning\\nApproach for Despeckling OCT\\nImages\\nShreyash Sahare\\nMachine Learning Engineer | Ex-Data Scientist at Parlay Finance\\n| 3+ Years in Predictive Modeling, LLMs & Scalable ML Pipelines |\\nPython, SQL, R | Deep Learning, Fine-Tuning, GenAI\\nBoulder, Colorado, United States\\nSummary\\nI'm a Machine Learning Engineer and Data Scientist with a strong\\nbackground in AI, data engineering, and software systems. I enjoy\\nbuilding end-to-end machine learning solutions—whether that's\\ndesigning scalable ETL pipelines, training predictive models, or\\ndeploying real-time analytics systems in the cloud.\\nOver the past few years, I’ve worked on projects across finance,\\nsupply chain, and healthcare. From creating SBA loan classifiers that\\nimproved approval workflows, to building explainable AI tools with\\nSHAP and LIME, to developing semantic search systems using RAG\\nand GPT-4o—I’ve had the chance to solve meaningful problems with\\na mix of ML, data engineering, and creativity.\\nI’m comfortable working across the stack: Dockerized pipelines\\nwith Airflow, MLOps with MLflow, and cloud platforms like AWS,\\nGCP, and Azure are part of my regular toolkit. I also love diving into\\nGenAI and LLMs—especially exploring how they can make decision\\nsystems more transparent and user-friendly.\\nAt the end of the day, I care about more than just accuracy. I like\\nto think about how models will actually be used—how they can be\\ntrusted, interpreted, and tied to real business outcomes. I’m always\\nopen to learning, collaborating, and pushing the boundaries of what’s\\npossible with AI and data.\\nExperience\\nVoid Robotics\\nRobotics Engineering Intern\\nAugust 2025\\xa0-\\xa0Present\\xa0(4 months)\\nMarathon, Florida, United States\\n\\xa0 Page 1 of 4\\xa0 \\xa0\\nAs a Robotics Engineering Intern at Void Robotics, I worked at the intersection\\nof AI and robotics by developing perception and computer vision pipelines\\nwithin ROS2. I built a pill-counting system across 50+ images using K-Means\\nclustering and advanced CV techniques such as Lab color space conversion,\\nthresholding, watershed, and masking to accurately detect and mark objects.\\nBuilding on this foundation, I expanded into robotics AI by implementing\\nSLAM-based autonomous navigation in ROS2 and deploying YOLO-driven\\nobject detection in Docker for real-time robotic perception, establishing a\\nscalable path toward intelligent, data-driven robotic systems.\\nMercor\\nData Science Expert\\nAugust 2025\\xa0-\\xa0September 2025\\xa0(2 months)\\nSan Francisco, California, United States\\nAs an Independent Contractor at Mercor, I was expected to execute end-\\nto-end data science tasks and evaluate the reasoning capabilities of state-\\nof-the-art LLMs. I completed 20+ projects across diverse datasets involving\\nhypothesis testing, time series forecasting, clustering, and data preprocessing,\\nwhile also creating visualizations and insights. Beyond analysis, I crafted\\nchallenging prompts for LLMs, authored expert golden responses, and\\ndeveloped detailed rubrics to benchmark model performance. These\\nevaluation frameworks consistently drove SOTA models to score below 50%,\\naveraging 27% across tasks, highlighting reasoning gaps and strengthening\\nthe rigor of AI evaluation.\\nParlay Finance\\nData Scientist\\nJanuary 2025\\xa0-\\xa0May 2025\\xa0(5 months)\\nAlexandria, Virginia, United States\\n- Developed an ML-powered SBA loan eligibility classification system using\\nXGBoost, LightGBM, TabTransformer, and Neural Networks, that achieved\\n87% accuracy and double-digit F1-score improvements through a stacked\\nensemble model. \\n- Generating a 200K+ row synthetic dataset simulating real-world loan\\napplications, applying SMOTE and random oversampling to balance five\\neligibility classes capped at 15K samples each\\n\\xa0 Page 2 of 4\\xa0 \\xa0\\n- Engineered key financial features (DSCR, DTI, liquidity scores) with\\npolynomial/log transformations, and integrated SHAP and LIME for model\\nexplainability and regulatory transparency. \\n- Reduced loan processing times from weeks to hours, enabling faster, fairer\\ncredit access for small businesses.\\nNational Institute of Technology, Tiruchirappalli\\nUndergraduate Research Intern\\nJune 2022\\xa0-\\xa0August 2022\\xa0(3 months)\\nTamil Nadu, India\\nAs an Undergraduate Research Intern under the guidance of my college\\nprofessor, I actively contributed to advancing medical imaging techniques\\nthrough cutting-edge research and development. My role involved designing a\\nnovel deep convolutional neural network, ResCoWNet, specifically tailored for\\nOptical Coherence Tomography (OCT) image despeckling, using Python and\\nTensorFlow.\\nMy work culminated in the publication of findings in a peer-reviewed journal,\\npositioning ResCoWNet as a benchmark in medical imaging. This experience\\nhoned my skills in machine learning for healthcare applications, academic\\nwriting, and data visualization, while deepening my understanding of advanced\\nimage processing techniques.\\nProbe, NIT Trichy\\n1 year 8 months\\nHead of Mentorship Program(Student Relations)\\nAugust 2021\\xa0-\\xa0August 2022\\xa0(1 year 1 month)\\nTiruchirappalli, Tamil Nadu, India\\nCoordinator\\nJanuary 2021\\xa0-\\xa0August 2021\\xa0(8 months)\\nTiruchirappalli, Tamil Nadu, India\\nPragyan - International Techno-managerial Organisation\\nManager, Crossfires and Guest Lectures\\nJuly 2021\\xa0-\\xa0August 2022\\xa0(1 year 2 months)\\nTiruchirappalli, Tamil Nadu, India\\nNational Institute of Technology, Tiruchirappalli\\nUndergraduate Research Assistant\\n\\xa0 Page 3 of 4\\xa0 \\xa0\\nJuly 2021\\xa0-\\xa0January 2022\\xa0(7 months)\\nTiruchirappalli, Tamil Nadu, India\\nEducation\\nUniversity of Colorado Boulder\\nMaster's degree,\\xa0Computer Science\\xa0·\\xa0(August 2023\\xa0-\\xa0May 2025)\\nNational Institute of Technology, Tiruchirappalli\\nBachelor of Technology - BTech,\\xa0Electronics and Communication\\nEngineering\\xa0·\\xa0(July 2019\\xa0-\\xa0May 2023)\\nCity International School, Wanowrie\\nStudent,\\xa0High School\\xa0·\\xa0(2017\\xa0-\\xa02019)\\nHutchings High School & Junior College\\nStudent,\\xa0Schooling\\xa0·\\xa0(2005\\xa0-\\xa02017)\\n\\xa0 Page 4 of 4\\n\\nWith this context, please chat with the user, always staying in character as Shreyash Sahare.\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Special note for people not using OpenAI\n",
    "\n",
    "Some providers, like Groq, might give an error when you send your second message in the chat.\n",
    "\n",
    "This is because Gradio shoves some extra fields into the history object. OpenAI doesn't mind; but some other models complain.\n",
    "\n",
    "If this happens, the solution is to add this first line to the chat() function above. It cleans up the history variable:\n",
    "\n",
    "```python\n",
    "history = [{\"role\": h[\"role\"], \"content\": h[\"content\"]} for h in history]\n",
    "```\n",
    "\n",
    "You may need to add this in other chat() callback functions in the future, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A lot is about to happen...\n",
    "\n",
    "1. Be able to ask an LLM to evaluate an answer\n",
    "2. Be able to rerun if the answer fails evaluation\n",
    "3. Put this together into 1 workflow\n",
    "\n",
    "All without any Agentic framework!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Pydantic model for the Evaluation\n",
    "\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class Evaluation(BaseModel):\n",
    "    is_acceptable: bool\n",
    "    feedback: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_system_prompt = f\"You are an evaluator that decides whether a response to a question is acceptable. \\\n",
    "You are provided with a conversation between a User and an Agent. Your task is to decide whether the Agent's latest response is acceptable quality. \\\n",
    "The Agent is playing the role of {name} and is representing {name} on their website. \\\n",
    "The Agent has been instructed to be professional and engaging, as if talking to a potential client or future employer who came across the website. \\\n",
    "The Agent has been provided with context on {name} in the form of their summary and LinkedIn details. Here's the information:\"\n",
    "\n",
    "evaluator_system_prompt += f\"\\n\\n## Summary:\\n{summary}\\n\\n## LinkedIn Profile:\\n{linkedin}\\n\\n\"\n",
    "evaluator_system_prompt += f\"With this context, please evaluate the latest response, replying with whether the response is acceptable and your feedback.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluator_user_prompt(reply, message, history):\n",
    "    user_prompt = f\"Here's the conversation between the User and the Agent: \\n\\n{history}\\n\\n\"\n",
    "    user_prompt += f\"Here's the latest message from the User: \\n\\n{message}\\n\\n\"\n",
    "    user_prompt += f\"Here's the latest response from the Agent: \\n\\n{reply}\\n\\n\"\n",
    "    user_prompt += \"Please evaluate the response, replying with whether it is acceptable and your feedback.\"\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(reply, message, history) -> Evaluation:\n",
    "\n",
    "    messages = [{\"role\": \"system\", \"content\": evaluator_system_prompt}] + [{\"role\": \"user\", \"content\": evaluator_user_prompt(reply, message, history)}]\n",
    "    response = openai.beta.chat.completions.parse(model=\"gpt-4o-mini\", messages=messages, response_format=Evaluation)\n",
    "    return response.choices[0].message.parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{\"role\": \"system\", \"content\": system_prompt}] + [{\"role\": \"user\", \"content\": \"do you hold a snowflake certification?\"}]\n",
    "response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "reply = response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Yes, I hold the Snowflake Snowpro Core certification. This certification validates my proficiency in using Snowflake, particularly in data management and analytics. If you have any specific questions about my experience with Snowflake or related projects, feel free to ask!'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Evaluation(is_acceptable=True, feedback=\"The Agent's response is acceptable. It accurately confirms that Shreyash Sahare holds the Snowflake Snowpro Core certification and provides relevant context about what the certification entails. Furthermore, the Agent invites further questions, which fosters engagement and maintains professionalism.\")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(reply, \"do you hold a snowflake certification?\", messages[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerun(reply, message, history, feedback):\n",
    "    updated_system_prompt = system_prompt + \"\\n\\n## Previous answer rejected\\nYou just tried to reply, but the quality control rejected your reply\\n\"\n",
    "    updated_system_prompt += f\"## Your attempted answer:\\n{reply}\\n\\n\"\n",
    "    updated_system_prompt += f\"## Reason for rejection:\\n{feedback}\\n\\n\"\n",
    "    messages = [{\"role\": \"system\", \"content\": updated_system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    if \"certification\" in message:\n",
    "        system = system_prompt + \"\\n\\nEverything in your reply needs to be in pig latin - \\\n",
    "              it is mandatory that you respond only and entirely in pig latin\"\n",
    "    else:\n",
    "        system = system_prompt\n",
    "    messages = [{\"role\": \"system\", \"content\": system}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "    reply =response.choices[0].message.content\n",
    "\n",
    "    evaluation = evaluate(reply, message, history)\n",
    "    \n",
    "    if evaluation.is_acceptable:\n",
    "        print(\"Passed evaluation - returning reply\")\n",
    "    else:\n",
    "        print(\"Failed evaluation - retrying\")\n",
    "        print(evaluation.feedback)\n",
    "        reply = rerun(reply, message, history, evaluation.feedback)       \n",
    "    return reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed evaluation - returning reply\n",
      "Passed evaluation - returning reply\n",
      "Failed evaluation - retrying\n",
      "The Agent's response is not acceptable as it uses 'Pig Latin' throughout instead of providing a clear and professional response. This formatting choice detracts from the professionalism expected in communication with a potential client or employer. The certifications themselves are relevant, but the way they are presented is cumbersome and unprofessional. A more straightforward answer without playfulness would be appropriate.\n"
     ]
    }
   ],
   "source": [
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
